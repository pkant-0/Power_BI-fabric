{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8H7VelylnCYv2kxIDRqw6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkant-0/Power_BI-fabric/blob/main/Untitled54.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data ingestion layer"
      ],
      "metadata": {
        "id": "MUwACD-zb2Aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnQXCru2bvTq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.ads import GoogleAdsClient\n",
        "from facebook_business.api import FacebookAdsApi\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import sqlalchemy\n",
        "\n",
        "class DataIngestionManager:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.blob_service_client = BlobServiceClient.from_connection_string(config['azure_storage_connection_string'])\n",
        "\n",
        "    def ingest_google_ads_data(self):\n",
        "        \"\"\"Ingest data from Google Ads API\"\"\"\n",
        "        google_ads_client = GoogleAdsClient.load_from_storage()\n",
        "        google_ads_service = google_ads_client.get_service('GoogleAdsService')\n",
        "\n",
        "        query = '''\n",
        "        SELECT\n",
        "            campaign.id,\n",
        "            metrics.impressions,\n",
        "            metrics.clicks,\n",
        "            metrics.cost_micros\n",
        "        FROM campaign\n",
        "        '''\n",
        "\n",
        "        google_ads_data = google_ads_client.search(query=query)\n",
        "        return self._transform_google_ads_data(google_ads_data)\n",
        "\n",
        "    def ingest_meta_ads_data(self):\n",
        "        \"\"\"Ingest data from Meta Ads API\"\"\"\n",
        "        FacebookAdsApi.init(access_token=self.config['meta_ads_token'])\n",
        "\n",
        "        # Fetch ad performance data\n",
        "        ad_insights = AdAccount(self.config['ad_account_id']).get_insights()\n",
        "        return self._transform_meta_ads_data(ad_insights)\n",
        "\n",
        "    def ingest_crm_data(self):\n",
        "        \"\"\"Extract CRM data using SQLAlchemy\"\"\"\n",
        "        engine = sqlalchemy.create_engine(self.config['crm_database_connection'])\n",
        "\n",
        "        query = \"\"\"\n",
        "        SELECT\n",
        "            customer_id,\n",
        "            total_spend,\n",
        "            last_purchase_date\n",
        "        FROM customer_transactions\n",
        "        \"\"\"\n",
        "\n",
        "        crm_data = pd.read_sql(query, engine)\n",
        "        return crm_data\n",
        "\n",
        "    def ingest_excel_data(self, file_path):\n",
        "        \"\"\"Ingest manual Excel uploads\"\"\"\n",
        "        excel_data = pd.read_excel(file_path)\n",
        "        return excel_data\n",
        "\n",
        "    def upload_to_blob_storage(self, data, container_name, blob_name):\n",
        "        \"\"\"Upload processed data to Azure Blob Storage\"\"\"\n",
        "        blob_client = self.blob_service_client.get_blob_client(\n",
        "            container=container_name,\n",
        "            blob=blob_name\n",
        "        )\n",
        "        blob_client.upload_blob(data.to_csv(index=False))\n",
        "\n",
        "# Data Transformation\n",
        "def data_transformation_pipeline(ingested_data):\n",
        "    \"\"\"Standardize and clean ingested data\"\"\"\n",
        "    # Data cleaning steps\n",
        "    cleaned_data = (\n",
        "        ingested_data\n",
        "        .dropna()\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Feature engineering\n",
        "    cleaned_data['conversion_rate'] = (\n",
        "        cleaned_data['conversions'] / cleaned_data['clicks']\n",
        "    )\n",
        "\n",
        "    return cleaned_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning model"
      ],
      "metadata": {
        "id": "nTxGgmFPcYL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import mlflow\n",
        "\n",
        "class MarketingPerformancePredictor:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def prepare_data(self, data):\n",
        "        \"\"\"Prepare features and target variable\"\"\"\n",
        "        features = [\n",
        "            'spend',\n",
        "            'impressions',\n",
        "            'clicks',\n",
        "            'conversion_rate'\n",
        "        ]\n",
        "\n",
        "        X = data[features]\n",
        "        y = data['total_revenue']\n",
        "\n",
        "        return train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    def train_model(self, X_train, y_train):\n",
        "        \"\"\"Train Gradient Boosting Regressor\"\"\"\n",
        "        with mlflow.start_run():\n",
        "            # Scale features\n",
        "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "            # Train model\n",
        "            self.model = GradientBoostingRegressor(\n",
        "                n_estimators=100,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=3\n",
        "            )\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Log model metrics\n",
        "            mlflow.log_metric(\"r2_score\", self.model.score(X_train_scaled, y_train))\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        return self.model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "u53B5T_rb8lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dashboard and visualization"
      ],
      "metadata": {
        "id": "h05SiyrHcdpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "\n",
        "class MarketingDashboard:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.app = dash.Dash(__name__)\n",
        "\n",
        "    def create_dashboard(self):\n",
        "        \"\"\"Create interactive marketing performance dashboard\"\"\"\n",
        "        self.app.layout = html.Div([\n",
        "            # Spend by Platform\n",
        "            dcc.Graph(\n",
        "                figure=px.bar(\n",
        "                    self.data.groupby('platform')['spend'].sum(),\n",
        "                    title='Total Spend by Platform'\n",
        "                )\n",
        "            ),\n",
        "\n",
        "            # Conversion Rate Trends\n",
        "            dcc.Graph(\n",
        "                figure=px.line(\n",
        "                    self.data,\n",
        "                    x='date',\n",
        "                    y='conversion_rate',\n",
        "                    color='platform'\n",
        "                )\n",
        "            )\n",
        "        ])\n",
        "\n",
        "    def run_dashboard(self):\n",
        "        self.app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "6FWwN6SPb8iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Orchestration and workflow"
      ],
      "metadata": {
        "id": "jMYTLRhJciHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "\n",
        "def marketing_data_pipeline():\n",
        "    # Initialize data ingestion\n",
        "    ingestion_manager = DataIngestionManager(config)\n",
        "\n",
        "    # Collect data from multiple sources\n",
        "    google_ads_data = ingestion_manager.ingest_google_ads_data()\n",
        "    meta_ads_data = ingestion_manager.ingest_meta_ads_data()\n",
        "    crm_data = ingestion_manager.ingest_crm_data()\n",
        "\n",
        "    # Combine and transform data\n",
        "    combined_data = pd.concat([\n",
        "        google_ads_data,\n",
        "        meta_ads_data,\n",
        "        crm_data\n",
        "    ])\n",
        "\n",
        "    transformed_data = data_transformation_pipeline(combined_data)\n",
        "\n",
        "    # Train ML model\n",
        "    predictor = MarketingPerformancePredictor()\n",
        "    X_train, X_test, y_train, y_test = predictor.prepare_data(transformed_data)\n",
        "    predictor.train_model(X_train, y_train)\n",
        "\n",
        "    # Create dashboard\n",
        "    dashboard = MarketingDashboard(transformed_data)\n",
        "    dashboard.create_dashboard()"
      ],
      "metadata": {
        "id": "I_DoPz3Ib8fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Components & Best Practices\n",
        "Data Ingestion\n",
        "\n",
        "Multi-source data collection\n",
        "API integrations\n",
        "Secure credential management\n",
        "Error handling\n",
        "Data Transformation\n",
        "\n",
        "Standardized cleaning\n",
        "Feature engineering\n",
        "Data quality checks\n",
        "Machine Learning\n",
        "\n",
        "Gradient Boosting Regressor\n",
        "MLflow for experiment tracking\n",
        "Model performance logging\n",
        "Visualization\n",
        "\n",
        "Interactive Plotly Dash\n",
        "Real-time updates\n",
        "Multiple visualization types\n",
        "Orchestration\n",
        "\n",
        "Apache Airflow for workflow management\n",
        "Scheduled data pipeline execution\n",
        "Recommended Cloud Infrastructure\n",
        "Azure Services\n",
        "Data Factory\n",
        "Blob Storage\n",
        "Machine Learning Studio\n",
        "Power BI\n",
        "Databricks\n",
        "Deployment Considerations\n",
        "Containerize with Docker\n",
        "Use Kubernetes for scaling\n",
        "Implement CI/CD pipelines\n",
        "Set up monitoring and logging\n",
        "Estimated Cost & Performance\n",
        "Monthly Estimated Cost:\n",
        "500\n",
        "−\n",
        "500−1500\n",
        "Data Processing: 1-10 TB/month\n",
        "Update Frequency: Daily/Weekly\n",
        "Latency: Near real-time\n",
        "Compliance & Security\n",
        "GDPR compliance\n",
        "Data encryption\n",
        "Role-based access control\n",
        "Audit logging\n",
        "This comprehensive solution provides a robust, scalable marketing data pipeline that integrates multiple data sources, applies machine learning for predictive insights, and creates interactive visualizations."
      ],
      "metadata": {
        "id": "YRf-6zT4cpBS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gy_kgjl4cJds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}